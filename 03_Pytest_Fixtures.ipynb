{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Pytest_Fixtures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1B3VzBMI25NA0B+GEcEbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-110/testing-with-pytest/blob/main/03_Pytest_Fixtures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Highlights:\n",
        "* storing fixtures in conftest\n",
        "* Fixtures as setup/teardown\n",
        "* Fixture scopes (class, module, etc)\n",
        "* Auto-use fixtures"
      ],
      "metadata": {
        "id": "p-NX2w0lw4lM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__OyOeSP5A6x"
      },
      "source": [
        "# Simple data fixture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mz5aTjMFhVX",
        "outputId": "7772e82c-afdd-48aa-f88f-1f35414375f1"
      },
      "source": [
        "%%writefile test_fixtures.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def some_data():\n",
        "  return 42\n",
        "\n",
        "\n",
        "def test_some_data(some_data):\n",
        "  assert some_data == 42"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuCJTyPAF501",
        "outputId": "deda3ae7-d3ef-41d0-f5b5-286fd4eb12e6"
      },
      "source": [
        "!pytest test_fixtures.py -v"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_fixtures.py::test_some_data \u001b[32mPASSED\u001b[0m\u001b[36m                                  [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 1 passed in 0.02 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dhCs8kXF8IY",
        "outputId": "2c0309e2-958b-4b51-d170-5cba301e9a7c"
      },
      "source": [
        "%%writefile test_fixtures2.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def arg1():\n",
        "  return (2, 2)\n",
        "\n",
        "\n",
        "@pytest.fixture()\n",
        "def arg2():\n",
        "  return 5\n",
        "\n",
        "\n",
        "\n",
        "def test_some_data(arg1, arg2):\n",
        "  a, b = arg1\n",
        "  assert a + b == arg2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaHC9RvxGYi0",
        "outputId": "8784b2be-29e0-4d33-f394-b4e9b844b7b4"
      },
      "source": [
        "!pytest test_fixtures2.py -v"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_fixtures2.py::test_some_data \u001b[31mFAILED\u001b[0m\u001b[36m                                 [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[1m\u001b[31m________________________________ test_some_data ________________________________\u001b[0m\n",
            "\n",
            "arg1 = (2, 2), arg2 = 5\n",
            "\n",
            "\u001b[1m    def test_some_data(arg1, arg2):\u001b[0m\n",
            "\u001b[1m      a, b = arg1\u001b[0m\n",
            "\u001b[1m>     assert a + b == arg2\u001b[0m\n",
            "\u001b[1m\u001b[31mE     assert (2 + 2) == 5\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fixtures2.py\u001b[0m:16: AssertionError\n",
            "\u001b[1m\u001b[31m=========================== 1 failed in 0.03 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmHbu2Y5Ggf"
      },
      "source": [
        "# Storing fixtures in confest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuWzHn3CGaPr",
        "outputId": "2afce54a-8e7c-4815-aa05-a12702e51d31"
      },
      "source": [
        "%%writefile conftest.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def arg1():\n",
        "  return (2, 3)\n",
        "\n",
        "\n",
        "@pytest.fixture()\n",
        "def arg2():\n",
        "  return 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing conftest.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1tSPAxIHcb9",
        "outputId": "c6d5df68-11ef-4ac0-a637-007469443a6b"
      },
      "source": [
        "%%writefile test_fixtures3.py\n",
        "\n",
        "\n",
        "def test_some_conftest(arg1, arg2):\n",
        "  a, b = arg1\n",
        "  assert a + b == arg2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures3.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rI30KAeHm-e",
        "outputId": "c7bfdddb-b8e0-4b39-bdc3-48379a1cf7dd"
      },
      "source": [
        "%%writefile test_fixtures4.py\n",
        "\n",
        "\n",
        "def test_some_conftest(arg1, arg2):\n",
        "  a, b = arg1\n",
        "  assert a - b == arg2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures4.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3voBzXfvHfsg",
        "outputId": "c424699f-9550-4623-89a9-0b8c781f1450"
      },
      "source": [
        "!pytest -v -k conftest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollecting 3 items                                                             \u001b[0m\u001b[1m\rcollecting 4 items                                                             \u001b[0m\u001b[1m\rcollecting 6 items                                                             \u001b[0m\u001b[1m\rcollecting 6 items                                                             \u001b[0m\u001b[1m\rcollecting 6 items                                                             \u001b[0m\u001b[1m\rcollected 6 items / 4 deselected                                               \u001b[0m\n",
            "\n",
            "test_fixtures3.py::test_some_conftest \u001b[32mPASSED\u001b[0m\u001b[36m                             [ 50%]\u001b[0m\n",
            "test_fixtures4.py::test_some_conftest \u001b[31mFAILED\u001b[0m\u001b[36m                             [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[1m\u001b[31m______________________________ test_some_conftest ______________________________\u001b[0m\n",
            "\n",
            "arg1 = (2, 3), arg2 = 5\n",
            "\n",
            "\u001b[1m    def test_some_conftest(arg1, arg2):\u001b[0m\n",
            "\u001b[1m      a, b = arg1\u001b[0m\n",
            "\u001b[1m>     assert a - b == arg2\u001b[0m\n",
            "\u001b[1m\u001b[31mE     assert (2 - 3) == 5\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fixtures4.py\u001b[0m:5: AssertionError\n",
            "\u001b[1m\u001b[31m=============== 1 failed, 1 passed, 4 deselected in 0.06 seconds ===============\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cber8Nda5Jwm"
      },
      "source": [
        "# Fixtures to setup and teardown a database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSY_BG6oJsCK",
        "outputId": "50db9dbc-753a-443d-d41e-77476ba4c2ca"
      },
      "source": [
        "%%writefile conftest.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def my_db():\n",
        "  # Creating database\n",
        "  db = 'my_db'\n",
        "  yield db\n",
        "  del db\n",
        "  # Destroying database"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting conftest.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-hi3GytJ98F",
        "outputId": "de7f3bf0-9b75-46b6-99f3-c3ac2564d7d9"
      },
      "source": [
        "%%writefile test_fixtures5.py\n",
        "\n",
        "\n",
        "def test_some_conftest(my_db):\n",
        "  assert 5 == 5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures5.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ_yYSibHhXS",
        "outputId": "e55e00f0-ff9c-4ead-b441-522d324a32a4"
      },
      "source": [
        "!pytest --setupshow -v test_fixtures5.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_fixtures5.py::test_some_conftest \n",
            "      SETUP    F my_db\n",
            "        test_fixtures5.py::test_some_conftest (fixtures used: my_db)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F my_db\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 1 passed in 0.01 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1LfbtLQ5aJO"
      },
      "source": [
        "# Fixtures as a tuple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BqGe99JKTfJ",
        "outputId": "02050fe6-7ec2-4aba-baf8-0868f0dc1515"
      },
      "source": [
        "%%writefile test_fixtures6.py\n",
        "import pytest\n",
        "\n",
        "\n",
        "@pytest.fixture()\n",
        "def a_tuple():\n",
        "  return (1, 'dog', None, {'cat':  5})\n",
        "\n",
        "\n",
        "def test_a_tuple(a_tuple):\n",
        "  assert a_tuple[3]['cat'] == 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures6.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8frw3HgKK8UV",
        "outputId": "3eb406a9-4a4e-4ba3-f3a6-82a9125500fe"
      },
      "source": [
        "!pytest --setupshow -v test_fixtures6.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_fixtures6.py::test_a_tuple \n",
            "      SETUP    F a_tuple\n",
            "        test_fixtures6.py::test_a_tuple (fixtures used: a_tuple)\u001b[31mFAILED\u001b[0m\n",
            "      TEARDOWN F a_tuple\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[1m\u001b[31m_________________________________ test_a_tuple _________________________________\u001b[0m\n",
            "\n",
            "a_tuple = (1, 'dog', None, {'cat': 5})\n",
            "\n",
            "\u001b[1m    def test_a_tuple(a_tuple):\u001b[0m\n",
            "\u001b[1m>     assert a_tuple[3]['cat'] == 4\u001b[0m\n",
            "\u001b[1m\u001b[31mE     assert 5 == 4\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fixtures6.py\u001b[0m:10: AssertionError\n",
            "\u001b[1m\u001b[31m=========================== 1 failed in 0.03 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGjYhPsX5ftN"
      },
      "source": [
        "# Fixtures failing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O885CV9EK_j1",
        "outputId": "720cd73c-fb71-4aac-a121-d2b67ac64057"
      },
      "source": [
        "%%writefile test_fixtures7.py\n",
        "import pytest\n",
        "\n",
        "\n",
        "@pytest.fixture()\n",
        "def a_tuple():\n",
        "  assert True == False\n",
        "  return (1, 'dog', None, {'cat':  5})\n",
        "\n",
        "\n",
        "def test_a_tuple(a_tuple):\n",
        "  assert a_tuple[3]['cat'] == 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures7.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2T9Wt0sLS0w",
        "outputId": "6e2dea9b-139e-4fee-9d99-9e193718158e"
      },
      "source": [
        "!pytest --setupshow -v test_fixtures7.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_fixtures7.py::test_a_tuple \n",
            "      SETUP    F a_tuple\u001b[31mERROR\u001b[0m\n",
            "      TEARDOWN F a_tuple\n",
            "\n",
            "==================================== ERRORS ====================================\n",
            "________________________ ERROR at setup of test_a_tuple ________________________\n",
            "\n",
            "\u001b[1m    @pytest.fixture()\u001b[0m\n",
            "\u001b[1m    def a_tuple():\u001b[0m\n",
            "\u001b[1m>     assert True == False\u001b[0m\n",
            "\u001b[1m\u001b[31mE     assert True == False\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fixtures7.py\u001b[0m:6: AssertionError\n",
            "\u001b[1m\u001b[31m=========================== 1 error in 0.03 seconds ============================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeV3cYg45jS0"
      },
      "source": [
        "# Combining fixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc7r7HZnLTw_",
        "outputId": "2419593d-4540-4c47-92ea-f1dc89a1a171"
      },
      "source": [
        "%%writefile conftest.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def my_db():\n",
        "  # Creating database\n",
        "  db = 'my_db: '\n",
        "  yield db\n",
        "  del db\n",
        "  # Destroying database\n",
        "\n",
        "@pytest.fixture()\n",
        "def multiple_names():\n",
        "  return ['Amy', 'Aaron', 'Adam']\n",
        "\n",
        "\n",
        "@pytest.fixture()\n",
        "def db_with_multiple_names(my_db, multiple_names):\n",
        "  for name in multiple_names:\n",
        "    my_db += name\n",
        "  return my_db"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting conftest.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_1EiJkN7HN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6255a0-a9e2-496d-dc1d-96e0725e2c7e"
      },
      "source": [
        "%%writefile test_fixtures8.py\n",
        "\n",
        "def test_db_stuff(db_with_multiple_names):\n",
        "  assert 'Zach' in db_with_multiple_names\n",
        "\n",
        "def test_other_db_stuff(db_with_multiple_names):\n",
        "  assert 'Amy' in db_with_multiple_names\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixtures8.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqk6ceIoqD4_",
        "outputId": "331de92f-0ef4-4d0b-b2e0-1ffdfc43ef4d"
      },
      "source": [
        "!pytest test_fixtures8.py --setup-show -v"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollected 2 items                                                              \u001b[0m\n",
            "\n",
            "test_fixtures8.py::test_db_stuff \n",
            "      SETUP    F my_db\n",
            "      SETUP    F multiple_names\n",
            "      SETUP    F db_with_multiple_names (fixtures used: multiple_names, my_db)\n",
            "        test_fixtures8.py::test_db_stuff (fixtures used: db_with_multiple_names, multiple_names, my_db)\u001b[31mFAILED\u001b[0m\n",
            "      TEARDOWN F db_with_multiple_names\n",
            "      TEARDOWN F multiple_names\n",
            "      TEARDOWN F my_db\n",
            "test_fixtures8.py::test_other_db_stuff \n",
            "      SETUP    F my_db\n",
            "      SETUP    F multiple_names\n",
            "      SETUP    F db_with_multiple_names (fixtures used: multiple_names, my_db)\n",
            "        test_fixtures8.py::test_other_db_stuff (fixtures used: db_with_multiple_names, multiple_names, my_db)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F db_with_multiple_names\n",
            "      TEARDOWN F multiple_names\n",
            "      TEARDOWN F my_db\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[1m\u001b[31m________________________________ test_db_stuff _________________________________\u001b[0m\n",
            "\n",
            "db_with_multiple_names = 'my_db: AmyAaronAdam'\n",
            "\n",
            "\u001b[1m    def test_db_stuff(db_with_multiple_names):\u001b[0m\n",
            "\u001b[1m>     assert 'Zach' in db_with_multiple_names\u001b[0m\n",
            "\u001b[1m\u001b[31mE     AssertionError: assert 'Zach' in 'my_db: AmyAaronAdam'\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fixtures8.py\u001b[0m:3: AssertionError\n",
            "\u001b[1m\u001b[31m====================== 1 failed, 1 passed in 0.03 seconds ======================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBNv0Vmi5oA1"
      },
      "source": [
        "# Fixture scopes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHwqSi8DqGni",
        "outputId": "cc4789f7-be9e-489a-b589-c63efc82e11a"
      },
      "source": [
        "%%writefile conftest.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture(scope='function')\n",
        "def my_func_stuff():\n",
        "  cache = {}\n",
        "  yield cache\n",
        "  del cache\n",
        "\n",
        "@pytest.fixture(scope='class')\n",
        "def my_class_stuff():\n",
        "  class_info = []\n",
        "  yield class_info\n",
        "  del class_info\n",
        "\n",
        "@pytest.fixture(scope='module')\n",
        "def my_module_stuff():\n",
        "  module_things = set()\n",
        "  yield module_things\n",
        "  del module_things\n",
        "\n",
        "@pytest.fixture(scope='session')\n",
        "def my_session_stuff():\n",
        "  session_stuff = {}\n",
        "  yield session_stuff\n",
        "  del session_stuff\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting conftest.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm60_wg6sGMZ",
        "outputId": "8bea6d71-372b-4255-9487-6cb3c46c9d67"
      },
      "source": [
        "%%writefile test_fixture_scope1.py\n",
        "import pytest\n",
        "\n",
        "def test_a(my_func_stuff, my_module_stuff, my_session_stuff):\n",
        "  assert 1 == 1\n",
        "\n",
        "@pytest.mark.usefixtures('my_class_stuff', 'my_module_stuff', 'my_session_stuff')\n",
        "class TestB:\n",
        "  def test_c(self):\n",
        "    assert 1 == 1\n",
        "\n",
        "  def test_d(self):\n",
        "    assert 1 == 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixture_scope1.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQGO6jzFsysM",
        "outputId": "8d7f4c0e-8615-4705-9c3b-68ce8930b57a"
      },
      "source": [
        "%%writefile test_fixture_scope2.py\n",
        "def test_e(my_module_stuff, my_session_stuiff, my_func_stuff):\n",
        "  assert 1 == 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing test_fixture_scope2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWNGYxpcs8DB",
        "outputId": "51891036-0e58-4456-e135-8e3f6d144978"
      },
      "source": [
        "!pytest -k scope --setup-show "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollecting 3 items                                                             \u001b[0m\u001b[1m\rcollecting 4 items                                                             \u001b[0m\u001b[1m\rcollecting 5 items                                                             \u001b[0m\u001b[1m\rcollecting 6 items                                                             \u001b[0m\u001b[1m\rcollecting 7 items                                                             \u001b[0m\u001b[1m\rcollecting 8 items                                                             \u001b[0m\u001b[1m\rcollecting 9 items                                                             \u001b[0m\u001b[1m\rcollecting 10 items                                                            \u001b[0m\u001b[1m\rcollecting 11 items                                                            \u001b[0m\u001b[1m\rcollecting 13 items                                                            \u001b[0m\u001b[1m\rcollecting 15 items                                                            \u001b[0m\u001b[1m\rcollecting 15 items                                                            \u001b[0m\u001b[1m\rcollecting 15 items                                                            \u001b[0m\u001b[1m\rcollected 15 items / 9 deselected                                              \u001b[0m\n",
            "\n",
            "test_fixture_scope1.py \n",
            "SETUP    S my_session_stuff\n",
            "  SETUP    M my_module_stuff\n",
            "      SETUP    F my_func_stuff\n",
            "        test_fixture_scope1.py::test_a (fixtures used: my_func_stuff, my_module_stuff, my_session_stuff).\n",
            "      TEARDOWN F my_func_stuff\n",
            "    SETUP    C my_class_stuff\n",
            "        test_fixture_scope1.py::TestB::()::test_c (fixtures used: my_class_stuff, my_module_stuff, my_session_stuff).\n",
            "        test_fixture_scope1.py::TestB::()::test_d (fixtures used: my_class_stuff, my_module_stuff, my_session_stuff).\n",
            "    TEARDOWN C my_class_stuff\n",
            "  TEARDOWN M my_module_stuff\u001b[36m                                             [  0%]\u001b[0m\n",
            "test_fixture_scope2.py \n",
            "  SETUP    M my_module_stuffE\n",
            "  TEARDOWN M my_module_stuff\u001b[36m                                             [  0%]\u001b[0m\n",
            "test_scope.py EE\n",
            "TEARDOWN S my_session_stuff\n",
            "\n",
            "==================================== ERRORS ====================================\n",
            "___________________________ ERROR at setup of test_e ___________________________\n",
            "file /content/test_fixture_scope2.py, line 1\n",
            "  def test_e(my_module_stuff, my_session_stuiff, my_func_stuff):\n",
            "\u001b[31mE       fixture 'my_session_stuiff' not found\u001b[0m\n",
            "\u001b[31m>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, my_class_stuff, my_func_stuff, my_module_stuff, my_session_stuff, pytestconfig, record_property, record_xml_attribute, record_xml_property, recwarn, tmpdir, tmpdir_factory\u001b[0m\n",
            "\u001b[31m>       use 'pytest --fixtures [testpath]' for help on them.\u001b[0m\n",
            "\n",
            "/content/test_fixture_scope2.py:1\n",
            "______________________ ERROR at setup of TestStuff.test_1 ______________________\n",
            "file /content/test_scope.py, line 5\n",
            "    def test_1(self):\n",
            "\u001b[31mE       fixture 'class_scope' not found\u001b[0m\n",
            "\u001b[31m>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, my_class_stuff, my_func_stuff, my_module_stuff, my_session_stuff, pytestconfig, record_property, record_xml_attribute, record_xml_property, recwarn, tmpdir, tmpdir_factory\u001b[0m\n",
            "\u001b[31m>       use 'pytest --fixtures [testpath]' for help on them.\u001b[0m\n",
            "\n",
            "/content/test_scope.py:5\n",
            "______________________ ERROR at setup of TestStuff.test_2 ______________________\n",
            "file /content/test_scope.py, line 7\n",
            "    def test_2(self):\n",
            "\u001b[31mE       fixture 'class_scope' not found\u001b[0m\n",
            "\u001b[31m>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, my_class_stuff, my_func_stuff, my_module_stuff, my_session_stuff, pytestconfig, record_property, record_xml_attribute, record_xml_property, recwarn, tmpdir, tmpdir_factory\u001b[0m\n",
            "\u001b[31m>       use 'pytest --fixtures [testpath]' for help on them.\u001b[0m\n",
            "\n",
            "/content/test_scope.py:7\n",
            "\u001b[1m\u001b[31m=============== 3 passed, 9 deselected, 3 error in 0.06 seconds ================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV_DYLBp5rsS"
      },
      "source": [
        "# You can use autouse for fixtures that always get used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LG5cfQCtAOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df131fe9-aaee-4278-c24a-aa32e2a275b4"
      },
      "source": [
        "%%writefile test_auto.py\n",
        "import pytest\n",
        "import time\n",
        "\n",
        "@pytest.fixture(autouse=True,scope='session')\n",
        "def footer_session_scope():\n",
        "  yield\n",
        "  now = time.time()\n",
        "  print('------')\n",
        "  print('Finshed: ', now)\n",
        "  print('-------')\n",
        "\n",
        "@pytest.fixture(autouse=True)\n",
        "def footer_function_scope():\n",
        "  start = time.time()\n",
        "  yield\n",
        "  stop = time.time()\n",
        "  delta = stop - start\n",
        "  print('\\ntest duration:', delta, 'seconds')\n",
        "\n",
        "\n",
        "# The fixtures apply to both even though you didn't specify them.\n",
        "def test_1():\n",
        "  time.sleep(1)\n",
        "\n",
        "def test_2():\n",
        "  time.sleep(1.23)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_auto.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4FO0q5M6Ecm",
        "outputId": "b2b5f554-b0cb-4dc1-8fc9-e4e99b246e4f"
      },
      "source": [
        "!pytest test_auto.py -v -s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 2 items                                                             \u001b[0m\u001b[1m\rcollected 2 items                                                              \u001b[0m\n",
            "\n",
            "test_auto.py::test_1 \u001b[32mPASSED\u001b[0m('\\ntest duration:', 1.001974105834961, 'seconds')\n",
            "\n",
            "test_auto.py::test_2 \u001b[32mPASSED\u001b[0m('\\ntest duration:', 1.2321350574493408, 'seconds')\n",
            "------\n",
            "('Finshed: ', 1626801695.576027)\n",
            "-------\n",
            "\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 2 passed in 2.24 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeOV-kdgPrMC"
      },
      "source": [
        "Autouse is good, but generally should be avoided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAk4-U2AQVwQ"
      },
      "source": [
        "# Renaming Fixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1dv_7dC6G6s",
        "outputId": "6acd1913-aa28-4c41-d824-8e841c4a57b6"
      },
      "source": [
        "%%writefile test_rename.py\n",
        "import pytest\n",
        "\n",
        "# You can use 'name' instead of the actualy function name\n",
        "@pytest.fixture(name='answer')\n",
        "def answer_but_with_a_really_long_excessive_naming_choice():\n",
        "  \"\"\"Return the answer.\"\"\"\n",
        "  return 42\n",
        "\n",
        "\n",
        "def test_everything(answer):\n",
        "  assert answer == 42\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_rename.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBX8ULXRQz4O",
        "outputId": "eaa0069b-9848-44ae-c03d-f9c0210ef259"
      },
      "source": [
        "!pytest test_rename.py -v --setup-show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_rename.py::test_everything \n",
            "      SETUP    F answer\n",
            "        test_rename.py::test_everything (fixtures used: answer)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F answer\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 1 passed in 0.02 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjUADn6WQ278",
        "outputId": "1e6f07cf-6c6b-4da4-da36-8d09c21d06d5"
      },
      "source": [
        "!pytest --fixtures test_rename.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 1 item                                                              \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\u001b[32mcache\u001b[0m\n",
            "    Return a cache object that can persist state between testing sessions.\n",
            "    \n",
            "    cache.get(key, default)\n",
            "    cache.set(key, value)\n",
            "    \n",
            "    Keys must be a ``/`` separated value, where the first part is usually the\n",
            "    name of your plugin or application to avoid clashes with other cache users.\n",
            "    \n",
            "    Values can be any object handled by the json stdlib module.\n",
            "\u001b[32mcapsys\u001b[0m\n",
            "    Enable capturing of writes to ``sys.stdout`` and ``sys.stderr`` and make\n",
            "    captured output available via ``capsys.readouterr()`` method calls\n",
            "    which return a ``(out, err)`` namedtuple.  ``out`` and ``err`` will be ``text``\n",
            "    objects.\n",
            "\u001b[32mcapsysbinary\u001b[0m\n",
            "    Enable capturing of writes to ``sys.stdout`` and ``sys.stderr`` and make\n",
            "    captured output available via ``capsys.readouterr()`` method calls\n",
            "    which return a ``(out, err)`` tuple.  ``out`` and ``err`` will be ``bytes``\n",
            "    objects.\n",
            "\u001b[32mcapfd\u001b[0m\n",
            "    Enable capturing of writes to file descriptors ``1`` and ``2`` and make\n",
            "    captured output available via ``capfd.readouterr()`` method calls\n",
            "    which return a ``(out, err)`` tuple.  ``out`` and ``err`` will be ``text``\n",
            "    objects.\n",
            "\u001b[32mcapfdbinary\u001b[0m\n",
            "    Enable capturing of write to file descriptors 1 and 2 and make\n",
            "    captured output available via ``capfdbinary.readouterr`` method calls\n",
            "    which return a ``(out, err)`` tuple.  ``out`` and ``err`` will be\n",
            "    ``bytes`` objects.\n",
            "\u001b[32mdoctest_namespace\u001b[0m\n",
            "    Fixture that returns a :py:class:`dict` that will be injected into the namespace of doctests.\n",
            "\u001b[32mpytestconfig\u001b[0m\n",
            "    Session-scoped fixture that returns the :class:`_pytest.config.Config` object.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        def test_foo(pytestconfig):\n",
            "            if pytestconfig.getoption(\"verbose\"):\n",
            "                ...\n",
            "\u001b[32mrecord_property\u001b[0m\n",
            "    Add an extra properties the calling test.\n",
            "    User properties become part of the test report and are available to the\n",
            "    configured reporters, like JUnit XML.\n",
            "    The fixture is callable with ``(name, value)``, with value being automatically\n",
            "    xml-encoded.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        def test_function(record_property):\n",
            "            record_property(\"example_key\", 1)\n",
            "\u001b[32mrecord_xml_property\u001b[0m\n",
            "    (Deprecated) use record_property.\n",
            "\u001b[32mrecord_xml_attribute\u001b[0m\n",
            "    Add extra xml attributes to the tag for the calling test.\n",
            "    The fixture is callable with ``(name, value)``, with value being\n",
            "    automatically xml-encoded\n",
            "\u001b[32mcaplog\u001b[0m\n",
            "    Access and control log capturing.\n",
            "    \n",
            "    Captured logs are available through the following methods::\n",
            "    \n",
            "    * caplog.text            -> string containing formatted log output\n",
            "    * caplog.records         -> list of logging.LogRecord instances\n",
            "    * caplog.record_tuples   -> list of (logger_name, level, message) tuples\n",
            "    * caplog.clear()         -> clear captured records and formatted log output string\n",
            "\u001b[32mmonkeypatch\u001b[0m\n",
            "    The returned ``monkeypatch`` fixture provides these\n",
            "    helper methods to modify objects, dictionaries or os.environ::\n",
            "    \n",
            "        monkeypatch.setattr(obj, name, value, raising=True)\n",
            "        monkeypatch.delattr(obj, name, raising=True)\n",
            "        monkeypatch.setitem(mapping, name, value)\n",
            "        monkeypatch.delitem(obj, name, raising=True)\n",
            "        monkeypatch.setenv(name, value, prepend=False)\n",
            "        monkeypatch.delenv(name, raising=True)\n",
            "        monkeypatch.syspath_prepend(path)\n",
            "        monkeypatch.chdir(path)\n",
            "    \n",
            "    All modifications will be undone after the requesting\n",
            "    test function or fixture has finished. The ``raising``\n",
            "    parameter determines if a KeyError or AttributeError\n",
            "    will be raised if the set/deletion operation has no target.\n",
            "\u001b[32mrecwarn\u001b[0m\n",
            "    Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.\n",
            "    \n",
            "    See http://docs.python.org/library/warnings.html for information\n",
            "    on warning categories.\n",
            "\u001b[32mtmpdir_factory\u001b[0m\n",
            "    Return a TempdirFactory instance for the test session.\n",
            "\u001b[32mtmpdir\u001b[0m\n",
            "    Return a temporary directory path object\n",
            "    which is unique to each test function invocation,\n",
            "    created as a sub directory of the base temporary\n",
            "    directory.  The returned object is a `py.path.local`_\n",
            "    path object.\n",
            "    \n",
            "    .. _`py.path.local`: https://py.readthedocs.io/en/latest/path.html\n",
            "\n",
            "------------------------ fixtures defined from conftest ------------------------\n",
            "\u001b[32mmy_class_stuff\u001b[0m\n",
            "\u001b[31m    conftest.py:10: no docstring available\u001b[0m\n",
            "\u001b[32mmy_module_stuff\u001b[0m\n",
            "\u001b[31m    conftest.py:16: no docstring available\u001b[0m\n",
            "\u001b[32mmy_session_stuff\u001b[0m\n",
            "\u001b[31m    conftest.py:22: no docstring available\u001b[0m\n",
            "\u001b[32mmy_func_stuff\u001b[0m\n",
            "\u001b[31m    conftest.py:4: no docstring available\u001b[0m\n",
            "\n",
            "---------------------- fixtures defined from test_rename -----------------------\n",
            "\u001b[32manswer\u001b[0m\n",
            "    Return the answer.\n",
            "\n",
            "\u001b[1m\u001b[33m========================= no tests ran in 0.01 seconds =========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FkUGYH-R524"
      },
      "source": [
        "# Parametrizing Fixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jChgFVHRKPZ",
        "outputId": "90a180ab-280d-498b-eecf-8b975611613f"
      },
      "source": [
        "%%writefile test_params.py\n",
        "import pytest\n",
        "\n",
        "class Cat:\n",
        "  def __init__(self, name, age, power):\n",
        "    self.name = name\n",
        "    self.age = age\n",
        "    self.power = power\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return self.name\n",
        "\n",
        "cats = [Cat('felix', 50, 9),\n",
        "        Cat('pete', 12, 10),\n",
        "        Cat('sylvester', 35, 4)]\n",
        "\n",
        "\n",
        "@pytest.fixture(params=cats)\n",
        "def some_cat(request):\n",
        "  return request.param\n",
        "\n",
        "def test_add_some_cats(some_cat):\n",
        " \n",
        "  assert some_cat.name == 'pete'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_params.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHudFZUwTYdK",
        "outputId": "818e9014-67b8-4d25-f880-bf09b23fffbb"
      },
      "source": [
        "!pytest test_params.py -v -s --setup-show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 3 items                                                             \u001b[0m\u001b[1m\rcollected 3 items                                                              \u001b[0m\n",
            "\n",
            "test_params.py::test_add_some_cats[some_cat0] \n",
            "      SETUP    F some_cat[felix]\n",
            "        test_params.py::test_add_some_cats[some_cat0] (fixtures used: some_cat)\u001b[31mFAILED\u001b[0m\n",
            "      TEARDOWN F some_cat[felix]\n",
            "test_params.py::test_add_some_cats[some_cat1] \n",
            "      SETUP    F some_cat[pete]\n",
            "        test_params.py::test_add_some_cats[some_cat1] (fixtures used: some_cat)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F some_cat[pete]\n",
            "test_params.py::test_add_some_cats[some_cat2] \n",
            "      SETUP    F some_cat[sylvester]\n",
            "        test_params.py::test_add_some_cats[some_cat2] (fixtures used: some_cat)\u001b[31mFAILED\u001b[0m\n",
            "      TEARDOWN F some_cat[sylvester]\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[1m\u001b[31m________________________ test_add_some_cats[some_cat0] _________________________\u001b[0m\n",
            "\n",
            "some_cat = felix\n",
            "\n",
            "\u001b[1m    def test_add_some_cats(some_cat):\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m>     assert some_cat.name == 'pete'\u001b[0m\n",
            "\u001b[1m\u001b[31mE     AssertionError: assert 'felix' == 'pete'\u001b[0m\n",
            "\u001b[1m\u001b[31mE       - felix\u001b[0m\n",
            "\u001b[1m\u001b[31mE       + pete\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_params.py\u001b[0m:23: AssertionError\n",
            "\u001b[1m\u001b[31m________________________ test_add_some_cats[some_cat2] _________________________\u001b[0m\n",
            "\n",
            "some_cat = sylvester\n",
            "\n",
            "\u001b[1m    def test_add_some_cats(some_cat):\u001b[0m\n",
            "\u001b[1m    \u001b[0m\n",
            "\u001b[1m>     assert some_cat.name == 'pete'\u001b[0m\n",
            "\u001b[1m\u001b[31mE     AssertionError: assert 'sylvester' == 'pete'\u001b[0m\n",
            "\u001b[1m\u001b[31mE       - sylvester\u001b[0m\n",
            "\u001b[1m\u001b[31mE       + pete\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_params.py\u001b[0m:23: AssertionError\n",
            "\u001b[1m\u001b[31m====================== 2 failed, 1 passed in 0.04 seconds ======================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1iOGeSMa2fU"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3hVZwwna5hQ"
      },
      "source": [
        "* Create a test file called test_fixtures.py.\n",
        " \n",
        "* Write a few data fixturesfunctions with the @pytest.fixture() decoratorthat r eturn some data. Perhaps a list, or a dictionary, or a tuple.\n",
        " \n",
        "* For each fixture, write at least one test function that uses it.\n",
        " \n",
        "* Write two tests that use the same fixture.\n",
        " \n",
        "* Run pytest --setup-show test_fixtures.py. Are all the fixtures run before e very test?\n",
        " \n",
        "* Add scope=module to the fixture from Exercise 4.\n",
        " \n",
        "* Re-run pytest --setup-show test_fixtures.py. What changed?\n",
        " \n",
        "* For the fixture from Exercise 6, change return <data> to yield <data>.\n",
        " \n",
        "* Add print statements before and after the yield.\n",
        " \n",
        "* Run pytest -s -v test_fixtures.py. Does the output make sense?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pnUB2oqTbqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5249427b-f884-4ac0-dec7-d6aaea1df8bb"
      },
      "source": [
        "%%writefile test_fixtures.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def some_lists():\n",
        "  return ([1, 2, 3],\n",
        "          [4, 5, 6],\n",
        "          [7, 8, 9])\n",
        "\n",
        "@pytest.fixture()\n",
        "def some_dicts():\n",
        "  return (dict(name='paul',\n",
        "              location='home'),\n",
        "          dict(name='sasha',\n",
        "               location='bank'))\n",
        "\n",
        "@pytest.fixture(scope='module')\n",
        "def some_names():\n",
        "  return ('mildrid', 'silus', 'kwame')\n",
        "\n",
        "def test_dicts(some_dicts, some_names):\n",
        "  assert some_dicts[0]['name'] in ('paul', 'sasha')\n",
        "\n",
        "def test_lists(some_lists):\n",
        "  assert some_lists[0][1] == 2\n",
        "\n",
        "\n",
        "def test_names(some_names):\n",
        "  assert 'i' in some_names[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_fixtures.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cct2L-98cgDp",
        "outputId": "127b9ce7-dd48-4c01-afa9-ec9c72aea871"
      },
      "source": [
        "!pytest test_fixtures.py -v --setup-show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 3 items                                                             \u001b[0m\u001b[1m\rcollected 3 items                                                              \u001b[0m\n",
            "\n",
            "test_fixtures.py::test_dicts \n",
            "  SETUP    M some_names\n",
            "      SETUP    F some_dicts\n",
            "        test_fixtures.py::test_dicts (fixtures used: some_dicts, some_names)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F some_dicts\n",
            "test_fixtures.py::test_lists \n",
            "      SETUP    F some_lists\n",
            "        test_fixtures.py::test_lists (fixtures used: some_lists)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F some_lists\n",
            "test_fixtures.py::test_names \n",
            "        test_fixtures.py::test_names (fixtures used: some_names)\u001b[32mPASSED\u001b[0m\n",
            "  TEARDOWN M some_names\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 3 passed in 0.03 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LJ2EHotchRn",
        "outputId": "38436627-f229-437f-bbf0-e5b6556fcb41"
      },
      "source": [
        "%%writefile test_fixtures2.py\n",
        "import pytest\n",
        "\n",
        "@pytest.fixture()\n",
        "def some_lists():\n",
        "  return ([1, 2, 3],\n",
        "          [4, 5, 6],\n",
        "          [7, 8, 9])\n",
        "\n",
        "@pytest.fixture()\n",
        "def some_dicts():\n",
        "  return (dict(name='paul',\n",
        "              location='home'),\n",
        "          dict(name='sasha',\n",
        "               location='bank'))\n",
        "\n",
        "@pytest.fixture(scope='module')\n",
        "def some_names():\n",
        "  print('CREATING NAMES')\n",
        "  yield ('mildrid', 'silus', 'kwame')\n",
        "  print('DESTROYING NAMES')\n",
        "\n",
        "def test_dicts(some_dicts, some_names):\n",
        "  assert some_dicts[0]['name'] in ('paul', 'sasha')\n",
        "\n",
        "def test_lists(some_lists):\n",
        "  assert some_lists[0][1] == 2\n",
        "\n",
        "\n",
        "def test_names(some_names):\n",
        "  assert 'i' in some_names[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting test_fixtures2.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeYdv6vTdXxl",
        "outputId": "b29316e7-067e-48bf-9dfe-0abeb36ee647"
      },
      "source": [
        "!pytest test_fixtures2.py -v --setup-show -s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux2 -- Python 2.7.17, pytest-3.6.4, py-1.8.0, pluggy-0.7.1 -- /usr/bin/python2\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content, inifile:\n",
            "\u001b[1m\rcollecting 0 items                                                             \u001b[0m\u001b[1m\rcollecting 3 items                                                             \u001b[0m\u001b[1m\rcollected 3 items                                                              \u001b[0m\n",
            "\n",
            "test_fixtures2.py::test_dicts CREATING NAMES\n",
            "\n",
            "  SETUP    M some_names\n",
            "      SETUP    F some_dicts\n",
            "        test_fixtures2.py::test_dicts (fixtures used: some_dicts, some_names)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F some_dicts\n",
            "test_fixtures2.py::test_lists \n",
            "      SETUP    F some_lists\n",
            "        test_fixtures2.py::test_lists (fixtures used: some_lists)\u001b[32mPASSED\u001b[0m\n",
            "      TEARDOWN F some_lists\n",
            "test_fixtures2.py::test_names \n",
            "        test_fixtures2.py::test_names (fixtures used: some_names)\u001b[32mPASSED\u001b[0mDESTROYING NAMES\n",
            "\n",
            "  TEARDOWN M some_names\n",
            "\n",
            "\u001b[32m\u001b[1m=========================== 3 passed in 0.03 seconds ===========================\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}